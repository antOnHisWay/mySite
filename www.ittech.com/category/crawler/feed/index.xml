<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>爬虫归档 - IT Tech</title>
	<atom:link href="/category/crawler/feed/" rel="self" type="application/rss+xml" />
	<link>/category/crawler/</link>
	<description></description>
	<lastBuildDate>Sat, 09 Sep 2023 10:33:35 +0000</lastBuildDate>
	<language>zh-CN</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=6.3</generator>
	<item>
		<title>scapy 中文输出乱码问题</title>
		<link>/scapy-%e4%b8%ad%e6%96%87%e8%be%93%e5%87%ba%e4%b9%b1%e7%a0%81%e9%97%ae%e9%a2%98/</link>
		
		<dc:creator><![CDATA[admin]]></dc:creator>
		<pubDate>Thu, 07 Sep 2023 01:53:58 +0000</pubDate>
				<category><![CDATA[爬虫]]></category>
		<category><![CDATA[Scrapy]]></category>
		<guid isPermaLink="false">/?p=160</guid>

					<description><![CDATA[<p>scrapy crawl spridername -o items.json -s FEED_EXPORT_ENCODING=utf-8</p>
<p><a rel="nofollow" href="/scapy-%e4%b8%ad%e6%96%87%e8%be%93%e5%87%ba%e4%b9%b1%e7%a0%81%e9%97%ae%e9%a2%98/">scapy 中文输出乱码问题</a>最先出现在<a rel="nofollow" href="/">IT Tech</a>。</p>
]]></description>
										<content:encoded><![CDATA[<div id="article_content" class="article_content clearfix">
<div id="content_views" class="htmledit_views">
<p>scrapy crawl spridername -o items.json<strong> -s FEED_EXPORT_ENCODING=utf-8</strong></p>
</div>
<div>
<div></div>
</div>
</div>
<div id="treeSkill">
<div class="skill-tree-box"></div>
</div>
<p><a rel="nofollow" href="/scapy-%e4%b8%ad%e6%96%87%e8%be%93%e5%87%ba%e4%b9%b1%e7%a0%81%e9%97%ae%e9%a2%98/">scapy 中文输出乱码问题</a>最先出现在<a rel="nofollow" href="/">IT Tech</a>。</p>
]]></content:encoded>
					
		
		
			</item>
		<item>
		<title>scrapy</title>
		<link>/scrapy/</link>
		
		<dc:creator><![CDATA[admin]]></dc:creator>
		<pubDate>Mon, 07 Aug 2023 01:42:55 +0000</pubDate>
				<category><![CDATA[爬虫]]></category>
		<guid isPermaLink="false">/?p=157</guid>

					<description><![CDATA[<p>直接使用scrapy shell selector = scrapy.Selector(text="""&#60;ul&#62; ...: &#60;li&#62;1&#60;/li&#62; ...: &#60;li&#62;2&#60;/li&#62; ...: &#60;li&#62;3&#60;/li&#62; ...: &#60;li&#62;4&#60;/li&#62; ...: &#60;li&#62;5&#60;/li&#62; ...: &#60;li&#62;6&#60;/li&#62; ...: &#60;li&#62;7&#60;/li&#62; ...: &#60;li&#62;8&#60;/li&#62; ...: &#60;li&#62;9&#60;/li&#62; ...: &#60;li&#62;10&#60;/li&#62; ...: &#60;li&#62;11&#60;/li&#62; ...: &#60;li&#62;12&#60;/li&#62; ...: &#60;/ul&#62;""") In [13]: selector.css('ul li:nth-child(1)::text').get() Out[13]: '1' 直接使用scrapy shell 获取地址内容并解析： 在Scrapy程序中进入调试 import scrapy class MySpider(scrapy.Spider): name = "myspider" start_urls = [ "http://example.com/", "http://example.org/", "http://example.net/", ]...</p>
<p><a rel="nofollow" href="/scrapy/">scrapy</a>最先出现在<a rel="nofollow" href="/">IT Tech</a>。</p>
]]></description>
										<content:encoded><![CDATA[<h2>直接使用scrapy shell</h2>
<pre class="EnlighterJSRAW" data-enlighter-language="generic">selector = scrapy.Selector(text="""&lt;ul&gt;
   ...:     &lt;li&gt;1&lt;/li&gt;
   ...:     &lt;li&gt;2&lt;/li&gt;
   ...:     &lt;li&gt;3&lt;/li&gt;
   ...:     &lt;li&gt;4&lt;/li&gt;
   ...:     &lt;li&gt;5&lt;/li&gt;
   ...:     &lt;li&gt;6&lt;/li&gt;
   ...:     &lt;li&gt;7&lt;/li&gt;
   ...:     &lt;li&gt;8&lt;/li&gt;
   ...:     &lt;li&gt;9&lt;/li&gt;
   ...:     &lt;li&gt;10&lt;/li&gt;
   ...:     &lt;li&gt;11&lt;/li&gt;
   ...:     &lt;li&gt;12&lt;/li&gt;
   ...: &lt;/ul&gt;""")

In [13]: selector.css('ul li:nth-child(1)::text').get()
Out[13]: '1'</pre>
<p>直接使用scrapy shell 获取地址内容并解析：</p>
<pre class="EnlighterJSRAW" data-enlighter-language="generic"></pre>
<h2>在Scrapy程序中进入调试</h2>
<pre class="EnlighterJSRAW" data-enlighter-language="generic">import scrapy


class MySpider(scrapy.Spider):
    name = "myspider"
    start_urls = [
        "http://example.com/",
        "http://example.org/",
        "http://example.net/",
    ]

    def parse(self, response):
        # We want to inspect one specific response.
        if ".org" in response.url:
            from scrapy.shell import inspect_response

            inspect_response(response, self)

        # Rest of parsing code.</pre>
<p>运行程序</p>
<pre class="EnlighterJSRAW" data-enlighter-language="generic">scrapy crawl quotes</pre>
<p>play</p>
<pre class="EnlighterJSRAW" data-enlighter-language="generic">response.xpath('//h1[@class="fn"]')

view(response)</pre>
<p>如何返回scrapy</p>
<pre class="EnlighterJSRAW" data-enlighter-language="generic">^D （ctrl-D： mac）（ctrl-z：windows）
</pre>
<p>&nbsp;</p>
<p><a rel="nofollow" href="/scrapy/">scrapy</a>最先出现在<a rel="nofollow" href="/">IT Tech</a>。</p>
]]></content:encoded>
					
		
		
			</item>
	</channel>
</rss>
